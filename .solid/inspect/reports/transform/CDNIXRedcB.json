{
  "resolvedId": "C:/Users/quan.doan/Documents/GitHub/chat-web-client/src/helper/LiveKitHelper.ts",
  "transforms": [
    {
      "name": "__load__",
      "result": "import {\r\n  Participant,\r\n  RemoteParticipant,\r\n  RemoteTrack,\r\n  RemoteTrackPublication,\r\n  Room,\r\n  Track,\r\n  RoomEvent,\r\n  VideoPresets\r\n} from 'livekit-client';\r\n\r\nlet currentRoom: Room | undefined;\r\n\r\nconst state = {\r\n  isFrontFacing: false,\r\n  encoder: new TextEncoder(),\r\n  decoder: new TextDecoder(),\r\n  defaultDevices: new Map<MediaDeviceKind, string>(),\r\n  bitrateInterval: undefined as any,\r\n};\r\n\r\nenum DataPacket_Kind {\r\n  RELIABLE = 0,\r\n  LOSSY = 1,\r\n  UNRECOGNIZED = -1,\r\n}\r\n\r\nclass LiveKitHelper {\r\n  private serverUrl: string;\r\n  private apiKey: string;\r\n  private apiSecret: string;\r\n\r\n  constructor(serverUrl: string, apiKey: string, apiSecret: string) {\r\n    this.serverUrl = serverUrl;\r\n    this.apiKey = apiKey;\r\n    this.apiSecret = apiSecret;\r\n\r\n    // ------------------------------------------------------------------------------------------------\r\n\r\n\r\n    // // publish local camera and mic tracks\r\n    // await room.localParticipant.enableCameraAndMicrophone();\r\n\r\n\r\n  }\r\n\r\n  async connectToRoom(\r\n    url: string,\r\n    token: string\r\n  ) {\r\n\r\n    const roomOpts: RoomOptions = {\r\n      // adaptiveStream,\r\n      // dynacast,\r\n      publishDefaults: {\r\n        // simulcast,\r\n        videoSimulcastLayers: [VideoPresets.h90, VideoPresets.h216],\r\n        videoCodec: 'vp8',\r\n      },\r\n      videoCaptureDefaults: {\r\n        resolution: VideoPresets.h720.resolution,\r\n      },\r\n    };\r\n\r\n    const connectOpts: RoomConnectOptions = {\r\n      autoSubscribe: true,\r\n    };\r\n    // if (forceTURN) {\r\n    //   connectOpts.rtcConfig = {\r\n    //     iceTransportPolicy: 'relay',\r\n    //   };\r\n    // }\r\n    const room = new Room(roomOpts);\r\n\r\n    // startTime = Date.now();\r\n    await room.prepareConnection(url);\r\n    // const prewarmTime = Date.now() - startTime;\r\n    // console.log(`prewarmed connection in ${prewarmTime}ms`);\r\n\r\n    room\r\n      // .on(RoomEvent.ParticipantConnected, participantConnected)\r\n      // .on(RoomEvent.ParticipantDisconnected, participantDisconnected)\r\n      // .on(RoomEvent.DataReceived, this.handleData)\r\n      // .on(RoomEvent.Disconnected, handleRoomDisconnect)\r\n      .on(RoomEvent.TrackSubscribed, this.handleTrackSubscribed)\r\n      .on(RoomEvent.TrackUnsubscribed, this.handleTrackUnsubscribed)\r\n      .on(RoomEvent.ActiveSpeakersChanged, this.handleActiveSpeakerChange)\r\n      .on(RoomEvent.Disconnected, this.handleDisconnect)\r\n      .on(RoomEvent.Reconnecting, () => console.log('Reconnecting to room'))\r\n      .on(RoomEvent.Reconnected, async () => {\r\n        // console.log(\r\n        //   'Successfully reconnected. server',\r\n        //   await room.engine.getConnectedServerAddress(),\r\n        // );\r\n      })\r\n      .on(RoomEvent.LocalTrackPublished, (pub) => {\r\n        const track = pub.track as LocalAudioTrack;\r\n\r\n        // if (track instanceof LocalAudioTrack) {\r\n        //   const { calculateVolume } = createAudioAnalyser(track);\r\n\r\n        //   setInterval(() => {\r\n        //     $('local-volume')?.setAttribute('value', calculateVolume().toFixed(4));\r\n        //   }, 200);\r\n        // }\r\n        // renderParticipant(room.localParticipant);\r\n        // updateButtonsForPublishState();\r\n        // renderScreenShare(room);\r\n      })\r\n      // .on(RoomEvent.LocalTrackUnpublished, () => {\r\n      //   renderParticipant(room.localParticipant);\r\n      //   updateButtonsForPublishState();\r\n      //   renderScreenShare(room);\r\n      // })\r\n      .on(RoomEvent.RoomMetadataChanged, (metadata) => {\r\n        // console.log('new metadata for room', metadata);\r\n      })\r\n      // .on(RoomEvent.MediaDevicesChanged, handleDevicesChanged)\r\n      .on(RoomEvent.AudioPlaybackStatusChanged, () => {\r\n        // if (room.canPlaybackAudio) {\r\n        //   $('start-audio-button')?.setAttribute('disabled', 'true');\r\n        // } else {\r\n        //   $('start-audio-button')?.removeAttribute('disabled');\r\n        // }\r\n      })\r\n      // .on(RoomEvent.MediaDevicesError, (e: Error) => {\r\n      //   const failure = MediaDeviceFailure.getFailure(e);\r\n      //   console.log('media device failure', failure);\r\n      // })\r\n      .on(\r\n        RoomEvent.ConnectionQualityChanged,\r\n        (quality: ConnectionQuality, participant?: Participant) => {\r\n          // console.log('connection quality changed', participant?.identity, quality);\r\n        },\r\n      )\r\n      .on(RoomEvent.TrackSubscribed, (track, pub, participant) => {\r\n        // console.log('subscribed to track', pub.trackSid, participant.identity);\r\n        // renderParticipant(participant);\r\n        // renderScreenShare(room);\r\n      })\r\n      .on(RoomEvent.TrackUnsubscribed, (_, pub, participant) => {\r\n        // console.log('unsubscribed from track', pub.trackSid);\r\n        // renderParticipant(participant);\r\n        // renderScreenShare(room);\r\n      })\r\n      .on(RoomEvent.SignalConnected, async () => {\r\n        // const signalConnectionTime = Date.now() - startTime;\r\n        // console.log(`signal connection established in ${signalConnectionTime}ms`);\r\n        // // speed up publishing by starting to publish before it's fully connected\r\n        // // publishing is accepted as soon as signal connection has established\r\n        // if (shouldPublish) {\r\n        //   await room.localParticipant.enableCameraAndMicrophone();\r\n        //   console.log(`tracks published in ${Date.now() - startTime}ms`);\r\n        //   updateButtonsForPublishState();\r\n      })\r\n    try {\r\n      // debugger\r\n      await room.connect(url, token, connectOpts);\r\n      // const elapsed = Date.now() - startTime;\r\n      // console.log(\r\n      //   `successfully connected to ${room.name} in ${Math.round(elapsed)}ms`,\r\n      //   await room.engine.getConnectedServerAddress(),\r\n      // );\r\n    } catch (error: any) {\r\n      let message: any = error;\r\n      if (error.message) {\r\n        message = error.message;\r\n      }\r\n      // console.log('could not connect:', message);\r\n      return;\r\n    }\r\n    currentRoom = room;\r\n    // window.currentRoom = room;\r\n    // setButtonsForState(true);\r\n\r\n    // room.participants.forEach((participant) => {\r\n    //   participantConnected(participant);\r\n    // });\r\n    // participantConnected(room.localParticipant);\r\n\r\n    return room;\r\n  }\r\n\r\n  handleData(msg: Uint8Array, participant?: RemoteParticipant) {\r\n    // const str = state.decoder.decode(msg);\r\n    // const chat = <HTMLTextAreaElement>$('chat');\r\n    // let from = 'server';\r\n    // if (participant) {\r\n    //   from = participant.identity;\r\n    // }\r\n    // chat.value += `${from}: ${str}\\n`;\r\n    debugger\r\n    return state.decoder.decode(msg);\r\n  }\r\n\r\n  disconnectRoom() {\r\n    if (currentRoom) {\r\n      currentRoom.disconnect();\r\n    }\r\n    // if (state.bitrateInterval) {\r\n    //   clearInterval(state.bitrateInterval);\r\n    // }\r\n  }\r\n\r\n  enterText(value: string) {\r\n    if (!currentRoom) return false;\r\n    if (value) {\r\n      const msg = state.encoder.encode(value);\r\n      currentRoom.localParticipant.publishData(msg, DataPacket_Kind.RELIABLE);\r\n      // (<HTMLTextAreaElement>(\r\n      //   $('chat')\r\n      // )).value += `${currentRoom.localParticipant.identity} (me): ${textField.value}\\n`;\r\n      // textField.value = '';\r\n      return true\r\n    }\r\n    return false\r\n  }\r\n\r\n  async toggleAudio() {\r\n    if (!currentRoom) return;\r\n    const enabled = currentRoom.localParticipant.isMicrophoneEnabled;\r\n    // setButtonDisabled('toggle-audio-button', true);\r\n    if (enabled) {\r\n      console.log('disabling audio');\r\n    } else {\r\n      console.log('enabling audio');\r\n    }\r\n    await currentRoom.localParticipant.setMicrophoneEnabled(!enabled);\r\n    // setButtonDisabled('toggle-audio-button', false);\r\n    // updateButtonsForPublishState();\r\n  }\r\n\r\n  async toggleVideo() {\r\n    if (!currentRoom) return;\r\n    // setButtonDisabled('toggle-video-button', true);\r\n    const enabled = currentRoom.localParticipant.isCameraEnabled;\r\n    if (enabled) {\r\n      console.log('disabling video');\r\n    } else {\r\n      console.log('enabling video');\r\n    }\r\n    await currentRoom.localParticipant.setCameraEnabled(!enabled);\r\n    // setButtonDisabled('toggle-video-button', false);\r\n    // renderParticipant(currentRoom.localParticipant);\r\n\r\n    // update display\r\n    // updateButtonsForPublishState();\r\n  }\r\n\r\n  flipVideo() {\r\n    const videoPub = currentRoom?.localParticipant.getTrack(Track.Source.Camera);\r\n    if (!videoPub) {\r\n      return;\r\n    }\r\n    // if (state.isFrontFacing) {\r\n    //   setButtonState('flip-video-button', 'Front Camera', false);\r\n    // } else {\r\n    //   setButtonState('flip-video-button', 'Back Camera', false);\r\n    // }\r\n    state.isFrontFacing = !state.isFrontFacing;\r\n    const options: VideoCaptureOptions = {\r\n      resolution: VideoPresets.h720.resolution,\r\n      facingMode: state.isFrontFacing ? 'user' : 'environment',\r\n    };\r\n    videoPub.videoTrack?.restartTrack(options);\r\n  }\r\n\r\n  async shareScreen() {\r\n    if (!currentRoom) return;\r\n\r\n    const enabled = currentRoom.localParticipant.isScreenShareEnabled;\r\n    console.log(`${enabled ? 'stopping' : 'starting'} screen share`);\r\n    // setButtonDisabled('share-screen-button', true);\r\n    await currentRoom.localParticipant.setScreenShareEnabled(!enabled, { audio: true });\r\n    // setButtonDisabled('share-screen-button', false);\r\n    // updateButtonsForPublishState();\r\n  }\r\n\r\n  startAudio() {\r\n    currentRoom?.startAudio();\r\n  }\r\n\r\n  handleTrackSubscribed(\r\n    track: RemoteTrack,\r\n    publication: RemoteTrackPublication,\r\n    participant: RemoteParticipant,\r\n  ) {\r\n    if (track.kind === Track.Kind.Video || track.kind === Track.Kind.Audio) {\r\n      // attach it to a new HTMLVideoElement or HTMLAudioElement\r\n      // parentElement.appendChild(element);\r\n    }\r\n    track.attach();\r\n  }\r\n\r\n\r\n  handleTrackUnsubscribed(\r\n    track: RemoteTrack,\r\n    publication: RemoteTrackPublication,\r\n    participant: RemoteParticipant,\r\n  ) {\r\n    // remove tracks from all attached elements\r\n    track.detach();\r\n  }\r\n\r\n  //  handleLocalTrackUnpublished(track: LocalTrackPublication, participant: LocalParticipant) {\r\n  //   // when local tracks are ended, update UI to remove them from rendering\r\n  //   track.detach();\r\n  // }\r\n\r\n  handleActiveSpeakerChange(speakers: Participant[]) {\r\n    // show UI indicators when participant is speaking\r\n  }\r\n\r\n  handleDisconnect() {\r\n    console.log('disconnected from room');\r\n  }\r\n}\r\n\r\nexport default LiveKitHelper;\r\n",
      "start": 1684204348427,
      "end": 1684204348427
    },
    {
      "name": "vite:esbuild",
      "result": "import {\n  Room,\n  Track,\n  RoomEvent,\n  VideoPresets\n} from \"livekit-client\";\nlet currentRoom;\nconst state = {\n  isFrontFacing: false,\n  encoder: new TextEncoder(),\n  decoder: new TextDecoder(),\n  defaultDevices: /* @__PURE__ */ new Map(),\n  bitrateInterval: void 0\n};\nvar DataPacket_Kind = /* @__PURE__ */ ((DataPacket_Kind2) => {\n  DataPacket_Kind2[DataPacket_Kind2[\"RELIABLE\"] = 0] = \"RELIABLE\";\n  DataPacket_Kind2[DataPacket_Kind2[\"LOSSY\"] = 1] = \"LOSSY\";\n  DataPacket_Kind2[DataPacket_Kind2[\"UNRECOGNIZED\"] = -1] = \"UNRECOGNIZED\";\n  return DataPacket_Kind2;\n})(DataPacket_Kind || {});\nclass LiveKitHelper {\n  serverUrl;\n  apiKey;\n  apiSecret;\n  constructor(serverUrl, apiKey, apiSecret) {\n    this.serverUrl = serverUrl;\n    this.apiKey = apiKey;\n    this.apiSecret = apiSecret;\n  }\n  async connectToRoom(url, token) {\n    const roomOpts = {\n      // adaptiveStream,\n      // dynacast,\n      publishDefaults: {\n        // simulcast,\n        videoSimulcastLayers: [VideoPresets.h90, VideoPresets.h216],\n        videoCodec: \"vp8\"\n      },\n      videoCaptureDefaults: {\n        resolution: VideoPresets.h720.resolution\n      }\n    };\n    const connectOpts = {\n      autoSubscribe: true\n    };\n    const room = new Room(roomOpts);\n    await room.prepareConnection(url);\n    room.on(RoomEvent.TrackSubscribed, this.handleTrackSubscribed).on(RoomEvent.TrackUnsubscribed, this.handleTrackUnsubscribed).on(RoomEvent.ActiveSpeakersChanged, this.handleActiveSpeakerChange).on(RoomEvent.Disconnected, this.handleDisconnect).on(RoomEvent.Reconnecting, () => console.log(\"Reconnecting to room\")).on(RoomEvent.Reconnected, async () => {\n    }).on(RoomEvent.LocalTrackPublished, (pub) => {\n      const track = pub.track;\n    }).on(RoomEvent.RoomMetadataChanged, (metadata) => {\n    }).on(RoomEvent.AudioPlaybackStatusChanged, () => {\n    }).on(\n      RoomEvent.ConnectionQualityChanged,\n      (quality, participant) => {\n      }\n    ).on(RoomEvent.TrackSubscribed, (track, pub, participant) => {\n    }).on(RoomEvent.TrackUnsubscribed, (_, pub, participant) => {\n    }).on(RoomEvent.SignalConnected, async () => {\n    });\n    try {\n      await room.connect(url, token, connectOpts);\n    } catch (error) {\n      let message = error;\n      if (error.message) {\n        message = error.message;\n      }\n      return;\n    }\n    currentRoom = room;\n    return room;\n  }\n  handleData(msg, participant) {\n    debugger;\n    return state.decoder.decode(msg);\n  }\n  disconnectRoom() {\n    if (currentRoom) {\n      currentRoom.disconnect();\n    }\n  }\n  enterText(value) {\n    if (!currentRoom)\n      return false;\n    if (value) {\n      const msg = state.encoder.encode(value);\n      currentRoom.localParticipant.publishData(msg, 0 /* RELIABLE */);\n      return true;\n    }\n    return false;\n  }\n  async toggleAudio() {\n    if (!currentRoom)\n      return;\n    const enabled = currentRoom.localParticipant.isMicrophoneEnabled;\n    if (enabled) {\n      console.log(\"disabling audio\");\n    } else {\n      console.log(\"enabling audio\");\n    }\n    await currentRoom.localParticipant.setMicrophoneEnabled(!enabled);\n  }\n  async toggleVideo() {\n    if (!currentRoom)\n      return;\n    const enabled = currentRoom.localParticipant.isCameraEnabled;\n    if (enabled) {\n      console.log(\"disabling video\");\n    } else {\n      console.log(\"enabling video\");\n    }\n    await currentRoom.localParticipant.setCameraEnabled(!enabled);\n  }\n  flipVideo() {\n    const videoPub = currentRoom?.localParticipant.getTrack(Track.Source.Camera);\n    if (!videoPub) {\n      return;\n    }\n    state.isFrontFacing = !state.isFrontFacing;\n    const options = {\n      resolution: VideoPresets.h720.resolution,\n      facingMode: state.isFrontFacing ? \"user\" : \"environment\"\n    };\n    videoPub.videoTrack?.restartTrack(options);\n  }\n  async shareScreen() {\n    if (!currentRoom)\n      return;\n    const enabled = currentRoom.localParticipant.isScreenShareEnabled;\n    console.log(`${enabled ? \"stopping\" : \"starting\"} screen share`);\n    await currentRoom.localParticipant.setScreenShareEnabled(!enabled, { audio: true });\n  }\n  startAudio() {\n    currentRoom?.startAudio();\n  }\n  handleTrackSubscribed(track, publication, participant) {\n    if (track.kind === Track.Kind.Video || track.kind === Track.Kind.Audio) {\n    }\n    track.attach();\n  }\n  handleTrackUnsubscribed(track, publication, participant) {\n    track.detach();\n  }\n  //  handleLocalTrackUnpublished(track: LocalTrackPublication, participant: LocalParticipant) {\n  //   // when local tracks are ended, update UI to remove them from rendering\n  //   track.detach();\n  // }\n  handleActiveSpeakerChange(speakers) {\n  }\n  handleDisconnect() {\n    console.log(\"disconnected from room\");\n  }\n}\nexport default LiveKitHelper;\n",
      "start": 1684204348427,
      "end": 1684204348448,
      "order": "normal"
    },
    {
      "name": "vite:import-analysis",
      "result": "import {\n  Room,\n  Track,\n  RoomEvent,\n  VideoPresets\n} from \"/node_modules/.vite/deps/livekit-client.js?v=f9cc9616\";\nlet currentRoom;\nconst state = {\n  isFrontFacing: false,\n  encoder: new TextEncoder(),\n  decoder: new TextDecoder(),\n  defaultDevices: /* @__PURE__ */ new Map(),\n  bitrateInterval: void 0\n};\nvar DataPacket_Kind = /* @__PURE__ */ ((DataPacket_Kind2) => {\n  DataPacket_Kind2[DataPacket_Kind2[\"RELIABLE\"] = 0] = \"RELIABLE\";\n  DataPacket_Kind2[DataPacket_Kind2[\"LOSSY\"] = 1] = \"LOSSY\";\n  DataPacket_Kind2[DataPacket_Kind2[\"UNRECOGNIZED\"] = -1] = \"UNRECOGNIZED\";\n  return DataPacket_Kind2;\n})(DataPacket_Kind || {});\nclass LiveKitHelper {\n  serverUrl;\n  apiKey;\n  apiSecret;\n  constructor(serverUrl, apiKey, apiSecret) {\n    this.serverUrl = serverUrl;\n    this.apiKey = apiKey;\n    this.apiSecret = apiSecret;\n  }\n  async connectToRoom(url, token) {\n    const roomOpts = {\n      // adaptiveStream,\n      // dynacast,\n      publishDefaults: {\n        // simulcast,\n        videoSimulcastLayers: [VideoPresets.h90, VideoPresets.h216],\n        videoCodec: \"vp8\"\n      },\n      videoCaptureDefaults: {\n        resolution: VideoPresets.h720.resolution\n      }\n    };\n    const connectOpts = {\n      autoSubscribe: true\n    };\n    const room = new Room(roomOpts);\n    await room.prepareConnection(url);\n    room.on(RoomEvent.TrackSubscribed, this.handleTrackSubscribed).on(RoomEvent.TrackUnsubscribed, this.handleTrackUnsubscribed).on(RoomEvent.ActiveSpeakersChanged, this.handleActiveSpeakerChange).on(RoomEvent.Disconnected, this.handleDisconnect).on(RoomEvent.Reconnecting, () => console.log(\"Reconnecting to room\")).on(RoomEvent.Reconnected, async () => {\n    }).on(RoomEvent.LocalTrackPublished, (pub) => {\n      const track = pub.track;\n    }).on(RoomEvent.RoomMetadataChanged, (metadata) => {\n    }).on(RoomEvent.AudioPlaybackStatusChanged, () => {\n    }).on(\n      RoomEvent.ConnectionQualityChanged,\n      (quality, participant) => {\n      }\n    ).on(RoomEvent.TrackSubscribed, (track, pub, participant) => {\n    }).on(RoomEvent.TrackUnsubscribed, (_, pub, participant) => {\n    }).on(RoomEvent.SignalConnected, async () => {\n    });\n    try {\n      await room.connect(url, token, connectOpts);\n    } catch (error) {\n      let message = error;\n      if (error.message) {\n        message = error.message;\n      }\n      return;\n    }\n    currentRoom = room;\n    return room;\n  }\n  handleData(msg, participant) {\n    debugger;\n    return state.decoder.decode(msg);\n  }\n  disconnectRoom() {\n    if (currentRoom) {\n      currentRoom.disconnect();\n    }\n  }\n  enterText(value) {\n    if (!currentRoom)\n      return false;\n    if (value) {\n      const msg = state.encoder.encode(value);\n      currentRoom.localParticipant.publishData(msg, 0 /* RELIABLE */);\n      return true;\n    }\n    return false;\n  }\n  async toggleAudio() {\n    if (!currentRoom)\n      return;\n    const enabled = currentRoom.localParticipant.isMicrophoneEnabled;\n    if (enabled) {\n      console.log(\"disabling audio\");\n    } else {\n      console.log(\"enabling audio\");\n    }\n    await currentRoom.localParticipant.setMicrophoneEnabled(!enabled);\n  }\n  async toggleVideo() {\n    if (!currentRoom)\n      return;\n    const enabled = currentRoom.localParticipant.isCameraEnabled;\n    if (enabled) {\n      console.log(\"disabling video\");\n    } else {\n      console.log(\"enabling video\");\n    }\n    await currentRoom.localParticipant.setCameraEnabled(!enabled);\n  }\n  flipVideo() {\n    const videoPub = currentRoom?.localParticipant.getTrack(Track.Source.Camera);\n    if (!videoPub) {\n      return;\n    }\n    state.isFrontFacing = !state.isFrontFacing;\n    const options = {\n      resolution: VideoPresets.h720.resolution,\n      facingMode: state.isFrontFacing ? \"user\" : \"environment\"\n    };\n    videoPub.videoTrack?.restartTrack(options);\n  }\n  async shareScreen() {\n    if (!currentRoom)\n      return;\n    const enabled = currentRoom.localParticipant.isScreenShareEnabled;\n    console.log(`${enabled ? \"stopping\" : \"starting\"} screen share`);\n    await currentRoom.localParticipant.setScreenShareEnabled(!enabled, { audio: true });\n  }\n  startAudio() {\n    currentRoom?.startAudio();\n  }\n  handleTrackSubscribed(track, publication, participant) {\n    if (track.kind === Track.Kind.Video || track.kind === Track.Kind.Audio) {\n    }\n    track.attach();\n  }\n  handleTrackUnsubscribed(track, publication, participant) {\n    track.detach();\n  }\n  //  handleLocalTrackUnpublished(track: LocalTrackPublication, participant: LocalParticipant) {\n  //   // when local tracks are ended, update UI to remove them from rendering\n  //   track.detach();\n  // }\n  handleActiveSpeakerChange(speakers) {\n  }\n  handleDisconnect() {\n    console.log(\"disconnected from room\");\n  }\n}\nexport default LiveKitHelper;\n",
      "start": 1684204348448,
      "end": 1684204348449,
      "order": "normal"
    }
  ]
}
